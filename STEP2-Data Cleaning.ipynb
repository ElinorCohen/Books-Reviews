{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0634e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import  Counter\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import enchant\n",
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961e8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Complete_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34029e",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8070b5",
   "metadata": {},
   "source": [
    "## Reviews Rate:\n",
    "* it was amazing = 5 stars\n",
    "* really liked it = 4 stars\n",
    "* liked it = 3 stars\n",
    "* it was ok = 2 stars\n",
    "* did not like it = 1 star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4773d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rep = {'it was amazing':5,'really liked it':4, 'liked it':3, 'it was ok':2, 'did not like it':1}\n",
    "df['Review_rate']=df['Review_rate'].replace(to_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad078b",
   "metadata": {},
   "source": [
    "## Genres\n",
    "According to my classification, there are 8 general genres:\n",
    "* Fiction = 1\n",
    "* Nonfiction = 2\n",
    "* Young = 3\n",
    "* Adult = 4\n",
    "* Children = 5\n",
    "* Short = 6\n",
    "* Sequential = 7\n",
    "* New = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792bf6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Classics', 'Fantasy', 'Nonfiction', 'Historical', 'Fiction',\n",
       "       'Young', 'Childrens', 'Religion', 'Science', 'Poetry', 'Horror',\n",
       "       'History', 'Mystery', 'Travel', 'Romance', 'Philosophy',\n",
       "       'Christian', 'Sequential', 'Academic', 'Self', 'Language', 'Plays',\n",
       "       'Thriller', 'Cultural', 'Biography', 'Autobiography', 'Esoterica',\n",
       "       'Drama', 'Contemporary', 'Short', 'Crime', 'Feminism', 'Adventure',\n",
       "       'Food', 'Psychology', 'Holiday', 'Spirituality', 'Business',\n",
       "       'Novels', 'Apocalyptic', 'Inspirational', 'Realistic', 'Economics',\n",
       "       'Marriage', 'Book', 'Humor', 'Polyamorous', 'Womens', 'New',\n",
       "       'Erotica', 'Politics', 'War', 'Epic', 'Parenting', 'Gender',\n",
       "       'Education', 'Adult', 'Gothic', 'Paranormal', 'Animals', 'LGBT',\n",
       "       'Modern', 'Magical', 'Art', 'Dark', 'Suspense', 'Shapeshifters',\n",
       "       'Westerns', 'Leadership', 'How', 'Music', 'Medical', 'European',\n",
       "       'Literary', 'World', 'Military', 'Sports', 'Sociology',\n",
       "       'Christianity', 'Criticism', 'Literature', 'Northern', 'Mental',\n",
       "       'Death', 'Race', 'Health', 'Anthropology'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4858e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].replace(['Classics', 'Fantasy','Horror','Mystery', 'Romance','Thriller', 'Drama','Crime',\n",
    "                     'Adventure', 'Novels','Erotica','Gothic', 'Paranormal','Magical','Suspense', \n",
    "                     'Shapeshifters','Westerns', 'Literary', 'Literature', ], 'Fiction', inplace=True)\n",
    "df['Genre'].replace(['Historical','Religion', 'Science', 'Poetry','History','Travel','Philosophy', \n",
    "                     'Christian','Academic', 'Self', 'Language', 'Plays', 'Cultural', 'Biography',\n",
    "                     'Autobiography', 'Esoterica','Contemporary','Feminism','Food', 'Psychology', \n",
    "                     'Holiday', 'Spirituality', 'Business','Apocalyptic', 'Inspirational', \n",
    "                     'Realistic', 'Economics','Marriage', 'Book', 'Humor', 'Polyamorous', \n",
    "                     'Womens', 'Politics', 'War', 'Epic', 'Gender', 'Education','Animals', \n",
    "                     'LGBT', 'Modern', 'Art', 'Parenting', 'Dark','Leadership', 'How', 'Music',\n",
    "                     'Medical', 'European','World', 'Military', 'Sports', 'Sociology',\n",
    "                     'Christianity', 'Criticism','Northern', 'Mental','Death', 'Race', 'Health',\n",
    "                     'Anthropology'], 'Nonfiction', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc52fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fiction', 'Nonfiction', 'Young', 'Childrens', 'Sequential',\n",
       "       'Short', 'New', 'Adult'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98510503",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_dict = {'Fiction':1, 'Nonfiction':2, 'Young':3, 'Adult':4, 'Childrens':5, 'Short':6, 'Sequential':7, 'New':8}\n",
    "df['Genre'].replace(genres_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978da68d",
   "metadata": {},
   "source": [
    "## Cover\n",
    "Based on the cover types, I separated them into four groups:\n",
    "* Hardcover = 1\n",
    "* Paperback = 2\n",
    "* Online = 3\n",
    "* Audiobook = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b9c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cover'].replace(['Mass Market Paperback','Library Binding', 'Unknown Binding',\n",
    "                     'Trade Paperback','Paperback/Kindle'],'Paperback', inplace=True)\n",
    "df['Cover'].replace(['Kindle Edition', 'ebook','Nook'],'online', inplace=True)\n",
    "df['Cover'].replace(['Leather Bound', 'Board book','Slipcased Hardcover',\n",
    "                    'Capa dura'],'Hardcover', inplace=True)\n",
    "df['Cover'].replace(['Audio Cassette','Audio CD', 'Audible Audio',],'Audiobook', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a24845e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_dict = {'Hardcover':1, 'Paperback':2, 'online':3, 'Audiobook':4}\n",
    "df['Cover'].replace(cover_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233cfcb",
   "metadata": {},
   "source": [
    "## Author Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cf55287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Author_followers'].replace(',','',regex=True,inplace=True)\n",
    "df['Author_followers'] = df['Author_followers'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79419f1a",
   "metadata": {},
   "source": [
    "## Reviews Date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eca1026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_date'].replace(',','',regex=True,inplace=True)\n",
    "# Creating 3 columns of day, month and year\n",
    "day = []\n",
    "month = []\n",
    "year = []\n",
    "for date in df['Review_date']:\n",
    "    splitted_date = date.split(' ')\n",
    "    month.append(splitted_date[0])\n",
    "    day.append(splitted_date[1])\n",
    "    year.append(splitted_date[2])\n",
    "df['Review_day'] = day\n",
    "df['Review_month'] = month\n",
    "df['Review_year'] = year\n",
    "df.drop('Review_date',axis=1,inplace=True)\n",
    "\n",
    "# Convert the month to numbers\n",
    "mon_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "df['Review_month'].replace(mon_dict,inplace=True)\n",
    "df['Review_day'] = df['Review_day'].astype(int)\n",
    "df['Review_year'] = df['Review_year'].astype(int)\n",
    "\n",
    "# Cut the year column to 4 bins\n",
    "bins=[2000,2005,2010,2015,2030]\n",
    "labels=[1,2,3,4]\n",
    "df['Review_year']=pd.cut(df['Review_year'],bins,labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c3e9d",
   "metadata": {},
   "source": [
    "## Book's Year and Month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682ff8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}\n",
    "df['Month_of_book'].replace(month_dict,inplace=True)\n",
    "df['Year_of_book'] = df['Year_of_book'].astype(int)\n",
    "bins=[1900,1950,2000,2005,2010,2015,2030]\n",
    "labels=[1,2,3,4,5,6]\n",
    "df['Year_of_book']=pd.cut(df['Year_of_book'],bins,labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952763bb",
   "metadata": {},
   "source": [
    "## Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28b15298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pages'] = df['Pages'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4399c5",
   "metadata": {},
   "source": [
    "## Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c39b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(values):\n",
    "    min = np.min(values)\n",
    "    max = np.max(values)\n",
    "    norm = (values - min)/(max-min) \n",
    "    return(pd.DataFrame(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1071b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pages'] = normalize_column(df['Pages'])\n",
    "df['Author_followers'] = normalize_column(df['Author_followers'])\n",
    "df['Ratings_number'] = normalize_column(df['Ratings_number'])\n",
    "df['Reviews_number'] = normalize_column(df['Reviews_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13e2eb",
   "metadata": {},
   "source": [
    "## Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8d727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124846 entries, 0 to 124845\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count   Dtype   \n",
      "---  ------            --------------   -----   \n",
      " 0   Reviews           119163 non-null  object  \n",
      " 1   Reviews_link      124846 non-null  object  \n",
      " 2   Review_rate       124846 non-null  int64   \n",
      " 3   Ratings_number    124846 non-null  float64 \n",
      " 4   Reviews_number    124846 non-null  float64 \n",
      " 5   Total_rate        124846 non-null  float64 \n",
      " 6   Pages             124846 non-null  float64 \n",
      " 7   Year_of_book      124816 non-null  category\n",
      " 8   Month_of_book     124846 non-null  int64   \n",
      " 9   Author_followers  124846 non-null  float64 \n",
      " 10  Cover             124846 non-null  int64   \n",
      " 11  Genre             124846 non-null  int64   \n",
      " 12  Review_day        124846 non-null  int32   \n",
      " 13  Review_month      124846 non-null  int64   \n",
      " 14  Review_year       124846 non-null  category\n",
      "dtypes: category(2), float64(5), int32(1), int64(5), object(2)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1504f",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d8e30",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "395f3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows that have no review\n",
    "df.drop(df[df['Reviews'].isnull()].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c31ad100",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "Persons = []\n",
    "for rev in df['Reviews']:\n",
    "    Persons_Count = 0\n",
    "    n = nlp(rev).ents\n",
    "    for x in n:\n",
    "        if x.label_ == 'PERSON':\n",
    "            Persons_Count += 1\n",
    "    Persons.append(Persons_Count)\n",
    "df['Num_of_names'] = Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1545424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to lemmatize each word with its POS tag\n",
    " \n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66d8a6",
   "metadata": {},
   "source": [
    "## Tags:\n",
    "* Noun = 'n'\n",
    "* Verb = 'v'\n",
    "* Adverb = 'r'\n",
    "* Adjective = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20b06e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe = MWETokenizer([('i', 'love','this','book'),('i', 'loved','this','book'),('loved','this','book'),('love','this','book'), ('i', 'hate','this','book'),('one', 'of', 'the','worst','books'),('one', 'of', 'the','best','books'),('worst','book'),('best','book'),('not','good')], separator='_')\n",
    "reviews = []\n",
    "review_length = []\n",
    "Nouns = []\n",
    "Adj = []\n",
    "Adv = []\n",
    "Ver = []\n",
    "Others = []\n",
    "\n",
    "for rev in df['Reviews']:\n",
    "    rev.replace('\\n','')\n",
    "    # split into words\n",
    "    tokens = word_tokenize(rev)\n",
    "    #remove all tokens that are not english alphabetic and lower them\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    All_words = [word.lower() for word in tokens if d.check(word) and word.isalpha()]\n",
    "    #count words\n",
    "    review_length.append(len(All_words))\n",
    "    # join to a new review\n",
    "    updated_review = ' '.join(All_words) \n",
    "    new_tokens = mwe.tokenize(word_tokenize(updated_review))\n",
    "    # filter out stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['image', 'error'])\n",
    "    words = [w for w in new_tokens if w not in stop_words]\n",
    "    # counting the tag types\n",
    "    noun = 0\n",
    "    verb = 0\n",
    "    adj = 0\n",
    "    adv = 0\n",
    "    other = 0\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    for (word, tag) in tagged:\n",
    "        if pos_tagger(tag) == 'n':\n",
    "            noun +=1\n",
    "        elif pos_tagger(tag) == 'v':\n",
    "            verb +=1\n",
    "        if pos_tagger(tag) == 'a':\n",
    "            adj +=1\n",
    "        if pos_tagger(tag) == 'r':\n",
    "            adv +=1 \n",
    "        else:\n",
    "            other +=1\n",
    "    #lemmitizing of words\n",
    "    lemmitizer = WordNetLemmatizer()\n",
    "    lemma = []\n",
    "    words_tags = nltk.pos_tag(words)\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), words_tags))\n",
    "    for (word, tag) in wordnet_tagged:\n",
    "            if tag is None:\n",
    "                lemma.append(lemmitizer.lemmatize(word))\n",
    "            else:\n",
    "                lemma.append(lemmitizer.lemmatize(word,tag))\n",
    "\n",
    "    \n",
    "    if len(lemma)==0:\n",
    "        reviews.append(np.nan)\n",
    "    else:\n",
    "        reviews.append(lemma)\n",
    "    Nouns.append(noun)\n",
    "    Adj.append(adj)\n",
    "    Adv.append(adv)\n",
    "    Ver.append(verb)\n",
    "    Others.append(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "925a9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokenized'] = reviews\n",
    "df['Words_amount'] = review_length\n",
    "df['Noun'] = Nouns\n",
    "df['Adjective'] = Adj\n",
    "df['Adverb'] = Adv\n",
    "df['Verb'] = Ver\n",
    "df['Other_words'] = Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a73550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Tokenized'].isnull()].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2baa8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_rev = []\n",
    "for sen in df['Tokenized']:\n",
    "    rev=''\n",
    "    for w in sen:\n",
    "        rev+=w+' '\n",
    "    updated_rev.append(rev)\n",
    "df['Updated_Review'] = updated_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ff6f72a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    86858\n",
       "0    32044\n",
       "Name: Book_like, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the target column\n",
    "Like = []\n",
    "for rate in df['Review_rate']:\n",
    "    if rate<=3:\n",
    "        Like.append(0)\n",
    "    if rate>3:\n",
    "        Like.append(1)\n",
    "df['Book_like'] = Like\n",
    "df['Book_like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3071c19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32044\n",
       "1    31858\n",
       "Name: Book_like, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For ML\n",
    "df_c = df.drop(df[df['Book_like'] == 1].sample(n=55000, random_state=1).index)\n",
    "df_c['Book_like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "419cac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = ['loved','love','good','amaze','amazed','excellent','amazing','great','wonderful','beautiful','fantastic','incredible']\n",
    "negative_words = ['evil','horrible','hate','awful','bad','lack','lacks','low','stupid','disappoint','boring','bore','blah','fuck','dislike','disliked','terrible']\n",
    "pos = []\n",
    "neg = []\n",
    "for rev in df_c['Tokenized']:\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    for word in rev:\n",
    "        if word in negative_words:\n",
    "            neg_count += 1\n",
    "        elif word in positive_words:\n",
    "            pos_count += 1\n",
    "    pos.append(pos_count)\n",
    "    neg.append(neg_count)\n",
    "df_c['Positive'] = pos\n",
    "df_c['Negative'] = neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0bf5a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "group0 = 'not_good'\n",
    "group1 = 'i_love_this_book'\n",
    "group2 = 'i_loved_this_book'\n",
    "group3 = 'love_this_book'\n",
    "group4 = 'loved_this_book'\n",
    "group5 = 'i_hate_this_book'\n",
    "group6 = 'one_of_the_worst_books'\n",
    "group7 = 'one_of_the_best_books'\n",
    "group8 = 'worst_book'\n",
    "group9 = 'best_book'\n",
    "l0 = []\n",
    "l1 = []\n",
    "l2 = []\n",
    "l3 = []\n",
    "l4 = []\n",
    "l5 = []\n",
    "l6 = []\n",
    "l7 = []\n",
    "l8 = []\n",
    "l9 = []\n",
    "\n",
    "for rev in df_c['Tokenized']:\n",
    "    c0 = c1 = c2 = c3 = c4 = c5 = c6 = c7 = c8 = c9 = 0\n",
    "    for word in rev:\n",
    "        if word==group0:\n",
    "            c0+=1\n",
    "        elif word==group1:\n",
    "            c1+=1\n",
    "        elif word==group2:\n",
    "            c2+=1\n",
    "        elif word==group3:\n",
    "            c3+=1\n",
    "        elif word==group4:\n",
    "            c4+=1\n",
    "        elif word==group5:\n",
    "            c5+=1\n",
    "        elif word==group6:\n",
    "            c6+=1\n",
    "        elif word==group7:\n",
    "            c7+=1\n",
    "        elif word==group8:\n",
    "            c8+=1\n",
    "        elif word==group9:\n",
    "            c9+=1\n",
    "    \n",
    "    l0.append(c0) \n",
    "    l1.append(c1)\n",
    "    l2.append(c2) \n",
    "    l3.append(c3)\n",
    "    l4.append(c4) \n",
    "    l5.append(c5)\n",
    "    l6.append(c6) \n",
    "    l7.append(c7)\n",
    "    l8.append(c8) \n",
    "    l9.append(c9)\n",
    "\n",
    "df_c['not_good'] = l0 \n",
    "df_c['i_love_this_book'] = l1\n",
    "df_c['i_loved_this_book'] = l2\n",
    "df_c['love_this_book'] = l3\n",
    "df_c['loved_this_book'] = l4\n",
    "df_c['i_hate_this_book'] = l5\n",
    "df_c['one_of_the_worst_books'] = l6\n",
    "df_c['one_of_the_best_books'] = l7\n",
    "df_c['worst_book'] = l8\n",
    "df_c['best_book'] = l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66971ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "394aa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.to_csv('DATA_After_Cleaning.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "092af287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63890 entries, 0 to 124845\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   Reviews                 63890 non-null  object  \n",
      " 1   Reviews_link            63890 non-null  object  \n",
      " 2   Review_rate             63890 non-null  int64   \n",
      " 3   Ratings_number          63890 non-null  float64 \n",
      " 4   Reviews_number          63890 non-null  float64 \n",
      " 5   Total_rate              63890 non-null  float64 \n",
      " 6   Pages                   63890 non-null  float64 \n",
      " 7   Year_of_book            63890 non-null  category\n",
      " 8   Month_of_book           63890 non-null  int64   \n",
      " 9   Author_followers        63890 non-null  float64 \n",
      " 10  Cover                   63890 non-null  int64   \n",
      " 11  Genre                   63890 non-null  int64   \n",
      " 12  Review_day              63890 non-null  int32   \n",
      " 13  Review_month            63890 non-null  int64   \n",
      " 14  Review_year             63890 non-null  category\n",
      " 15  Num_of_names            63890 non-null  int64   \n",
      " 16  Tokenized               63890 non-null  object  \n",
      " 17  Words_amount            63890 non-null  int64   \n",
      " 18  Noun                    63890 non-null  int64   \n",
      " 19  Adjective               63890 non-null  int64   \n",
      " 20  Adverb                  63890 non-null  int64   \n",
      " 21  Verb                    63890 non-null  int64   \n",
      " 22  Other_words             63890 non-null  int64   \n",
      " 23  Updated_Review          63890 non-null  object  \n",
      " 24  Book_like               63890 non-null  int64   \n",
      " 25  Positive                63890 non-null  int64   \n",
      " 26  Negative                63890 non-null  int64   \n",
      " 27  not_good                63890 non-null  int64   \n",
      " 28  i_love_this_book        63890 non-null  int64   \n",
      " 29  i_loved_this_book       63890 non-null  int64   \n",
      " 30  love_this_book          63890 non-null  int64   \n",
      " 31  loved_this_book         63890 non-null  int64   \n",
      " 32  i_hate_this_book        63890 non-null  int64   \n",
      " 33  one_of_the_worst_books  63890 non-null  int64   \n",
      " 34  one_of_the_best_books   63890 non-null  int64   \n",
      " 35  worst_book              63890 non-null  int64   \n",
      " 36  best_book               63890 non-null  int64   \n",
      "dtypes: category(2), float64(5), int32(1), int64(25), object(4)\n",
      "memory usage: 17.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282dd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
