{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc81735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "import re\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6fcb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-65110014fa9c>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(PATH)\n",
    "url='https://www.goodreads.com/list/show/264.Books_That_Everyone_Should_Read_At_Least_Once'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f92e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the username and password\n",
    "text_file = open(\"keys.txt\", \"r\")\n",
    "keys = text_file.read().splitlines()\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757fc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div/header/div[1]/div/ul/li[1]/a')\n",
    "sign_in.click()                      \n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='user[email]']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='user[password]']\")))\n",
    "\n",
    "username.clear()\n",
    "username.send_keys(keys[0])\n",
    "password.clear()\n",
    "password.send_keys(keys[1])\n",
    "time.sleep(3)\n",
    "log_in = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[type='submit']\")))\n",
    "log_in.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0b02526",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [] #good\n",
    "review_rate = [] #good\n",
    "review_date = [] \n",
    "rating = [] \n",
    "num_of_ratings = []\n",
    "num_of_reviews = []\n",
    "num_of_pages = []\n",
    "published_year = []\n",
    "published_month = []\n",
    "author_followers = []\n",
    "cover_type = []\n",
    "genre = []\n",
    "\n",
    "rev_links=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394ae94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page_url='https://www.goodreads.com/list/show/264.Books_That_Everyone_Should_Read_At_Least_Once?page='\n",
    "pages=list(range(1,101))\n",
    "for page in pages:\n",
    "    time.sleep(5)\n",
    "    driver.get(page_url+str(page))\n",
    "    print('num of page',page)\n",
    "    try:\n",
    "        table=driver.find_element(By.CSS_SELECTOR,'#all_votes > table > tbody ')\n",
    "        rows=table.find_elements(By.TAG_NAME,'tr')\n",
    "        print(len(rows))\n",
    "    except:\n",
    "        driver.refresh()\n",
    "        time.sleep(5)\n",
    "        table=driver.find_element(By.CSS_SELECTOR,'#all_votes > table > tbody ')\n",
    "        rows=table.find_elements(By.TAG_NAME,'tr')\n",
    "        print(len(rows))\n",
    "        \n",
    "    # getting all the book links from current page\n",
    "    links=[]\n",
    "    for row in rows:\n",
    "        link=row.find_element(By.TAG_NAME,'a')\n",
    "        links.append(link.get_attribute('href'))\n",
    "    \n",
    "    # running over all the book links\n",
    "    for link in links:\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            driver.get(link)\n",
    "            time.sleep(5)   \n",
    "            \n",
    "            # book total rate\n",
    "            try:\n",
    "                rate=driver.find_element(By.XPATH,f\"//span[@itemprop='ratingValue']\").text\n",
    "                print(rate)\n",
    "            except:\n",
    "                rate=np.nan\n",
    "\n",
    "            # book pages\n",
    "            try:\n",
    "                pagesNumber =driver.find_element(By.XPATH,f\"//span[@itemprop='numberOfPages']\").text.split(\" \")[0]\n",
    "                print(pagesNumber)\n",
    "            except:\n",
    "                pagesNumber=np.nan\n",
    "\n",
    "            # ratings number\n",
    "            try:\n",
    "                ratingsNumber =driver.find_element(By.XPATH,f\"//meta[@itemprop='ratingCount']\").get_attribute('content')\n",
    "                print(ratingsNumber)\n",
    "            except:\n",
    "                ratingsNumber=np.nan\n",
    "                \n",
    "                \n",
    "            # reviews number\n",
    "            try:\n",
    "                reviewsNumber =driver.find_element(By.XPATH,f\"//meta[@itemprop='reviewCount']\").get_attribute('content')\n",
    "                print(reviewsNumber)\n",
    "            except:\n",
    "                reviewsNumber=np.nan\n",
    "\n",
    "            # book genre\n",
    "            try:\n",
    "                genre_table=driver.find_element(By.CSS_SELECTOR,\"body > div.content > div.mainContentContainer > div.mainContent > div.mainContentFloat > div.rightContainer > div:nth-child(6) > div > div.bigBoxBody > div \")\n",
    "                genres=genre_table.find_elements(By.CLASS_NAME,\"elementList\")\n",
    "                top_genre=genres[0].find_element(By.CLASS_NAME,'left').text.split(' ')[0]\n",
    "                print(top_genre)\n",
    "            except:\n",
    "                top_genre= np.nan\n",
    "    \n",
    "            # book published date\n",
    "            try:\n",
    "                d= driver.find_element(By.ID,'details') \n",
    "                date_str=d.find_elements(By.CLASS_NAME,'row')[1].text.split(' ')\n",
    "                string=\"\"\n",
    "                for w in date_str:\n",
    "                    string+=w+' '\n",
    "                year_pat='\\d\\d\\d\\d'\n",
    "                year_pat2='\\d\\d\\d'\n",
    "                mon_pat=\"January|February|March|April|May|June|July|August|September|October|November|December\"\n",
    "                try:\n",
    "                    month=re.findall(mon_pat,string)[0]\n",
    "                    print(month)\n",
    "                except:\n",
    "                    month=np.nan\n",
    "                try:\n",
    "                    try:\n",
    "                        year=re.findall(year_pat,string)[0]\n",
    "                        print(year)\n",
    "                    except:\n",
    "                        year2=re.findall(year_pat2,string)[0]\n",
    "                        print(year2)\n",
    "                except:\n",
    "                    year=np.nan\n",
    "\n",
    "            except:\n",
    "                year=np.nan\n",
    "                month=np.nan\n",
    "\n",
    "            # book cover\n",
    "            try:\n",
    "                cover =driver.find_element(By.XPATH,f\"//span[@itemprop='bookFormat']\").text\n",
    "                print(cover)\n",
    "            except:\n",
    "                cover=np.nan\n",
    "                \n",
    "            # book author followers\n",
    "            try:\n",
    "                followers=driver.find_element(By.CLASS_NAME,\"bookAuthorProfile__followerCount\").text.split(' ')[0]\n",
    "                print(followers)\n",
    "            except:\n",
    "                followers=np.nan\n",
    "\n",
    "            # getting all the reviews\n",
    "            try:\n",
    "                r=driver.find_element(By.CLASS_NAME,'leftContainer')\n",
    "                reviews_table=r.find_element(By.ID,'bookReviews')\n",
    "                reviews = reviews_table.find_elements(By.CLASS_NAME,'friendReviews')\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            # running over all reviews\n",
    "            for review in reviews:\n",
    "                \n",
    "                # getting the full review link\n",
    "                rev_link=review.find_element(By.TAG_NAME,'link').get_attribute('href')\n",
    "                rev_links.append(rev_link)\n",
    "                print('------------------------------------')\n",
    "                print(rev_link)\n",
    "                print('------------------------------------')\n",
    "\n",
    "                # getting the rate of the review\n",
    "                try:\n",
    "                    stars = review.find_element(By.CLASS_NAME,'staticStars').get_attribute('title')\n",
    "                    review_rate.append(stars)\n",
    "                    print(stars)\n",
    "                except:\n",
    "                    review_rate.append(np.nan)\n",
    "                    \n",
    "                # getting the review date\n",
    "                try:\n",
    "                    r_date=review.find_element(By.CLASS_NAME,'reviewDate').text\n",
    "                    review_date.append(r_date)\n",
    "                    print(r_date)\n",
    "                except:\n",
    "                    review_date.append(np.nan)\n",
    "                \n",
    "                rating.append(rate)\n",
    "                num_of_pages.append(pagesNumber)\n",
    "                num_of_ratings.append(ratingsNumber)\n",
    "                num_of_reviews.append(reviewsNumber)\n",
    "                genre.append(top_genre)\n",
    "                published_month.append(month)\n",
    "                try:\n",
    "                    published_year.append(year)\n",
    "                except:\n",
    "                    published_year.append(year2)\n",
    "                cover_type.append(cover)\n",
    "                author_followers.append(followers)\n",
    "\n",
    "        except:\n",
    "            driver.refresh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da8d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df= pd.DataFrame({'Reviews_link':rev_links,'Review_date':review_date, 'Review_rate':review_rate,'Ratings_number':num_of_ratings,'Reviews_number':num_of_reviews,'Total_rate':rating, 'Pages':num_of_pages,'Year_of_book':published_year, 'Month_of_book':published_month, 'Author_followers':author_followers, 'Cover':cover_type ,'Genre':genre})\n",
    "df.to_csv('Reviews_updated.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c8a9ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got help with the reviews links crawling and because of lack of time I minimized my dataframe to 150000 rows\n",
    "df.dropna(inplace=True)\n",
    "new_df=df[:150000]\n",
    "\n",
    "All_links=new_df['Reviews_link'].tolist()\n",
    "links1=All_links[:25000] #success\n",
    "links2=All_links[25000:50000] #success\n",
    "links3=All_links[50000:75000] #success\n",
    "links4=All_links[75000:100000] #24,846 success\n",
    "links5=All_links[100000:125000] #fail\n",
    "links6=All_links[125000:] #success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cc8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "i=1\n",
    "for l in links1:\n",
    "    try:\n",
    "        driver.get(l)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            text=driver.find_element(By.CLASS_NAME,'reviewText').text\n",
    "            reviews.append(text)\n",
    "            print('----',i,' / ',length,'------')\n",
    "            print(text)\n",
    "            print('----------------------')\n",
    "        except:\n",
    "            reviews.append(np.nan)\n",
    "        i+=1\n",
    "    except:\n",
    "        driver.refresh()\n",
    "\n",
    "to_save=pd.DataFrame({'reviews':reviews})  \n",
    "\n",
    "to_save.to_csv('Try1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616618ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "i=1\n",
    "for l in links2:\n",
    "    try:\n",
    "        driver.get(l)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            text=driver.find_element(By.CLASS_NAME,'reviewText').text\n",
    "            reviews.append(text)\n",
    "            print('----',i,' / ',length,'------')\n",
    "            print(text)\n",
    "            print('----------------------')\n",
    "        except:\n",
    "            reviews.append(np.nan)\n",
    "        i+=1\n",
    "    except:\n",
    "        driver.refresh()\n",
    "\n",
    "to_save=pd.DataFrame({'reviews':reviews})  \n",
    "\n",
    "to_save.to_csv('Try2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73261b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "i=1\n",
    "for l in links3:\n",
    "    try:\n",
    "        driver.get(l)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            text=driver.find_element(By.CLASS_NAME,'reviewText').text\n",
    "            reviews.append(text)\n",
    "            print('----',i,' / ',length,'------')\n",
    "            print(text)\n",
    "            print('----------------------')\n",
    "        except:\n",
    "            reviews.append(np.nan)\n",
    "        i+=1\n",
    "    except:\n",
    "        driver.refresh()\n",
    "\n",
    "to_save=pd.DataFrame({'reviews':reviews})  \n",
    "\n",
    "to_save.to_csv('Try3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "i=1\n",
    "for l in links4:\n",
    "    try:\n",
    "        driver.get(l)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            text=driver.find_element(By.CLASS_NAME,'reviewText').text\n",
    "            reviews.append(text)\n",
    "            print('----',i,' / ',length,'------')\n",
    "            print(text)\n",
    "            print('----------------------')\n",
    "        except:\n",
    "            reviews.append(np.nan)\n",
    "        i+=1\n",
    "    except:\n",
    "        driver.refresh()\n",
    "\n",
    "to_save=pd.DataFrame({'reviews':reviews})  \n",
    "\n",
    "to_save.to_csv('Try4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "i=1\n",
    "for l in links5:\n",
    "    try:\n",
    "        driver.get(l)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            text=driver.find_element(By.CLASS_NAME,'reviewText').text\n",
    "            reviews.append(text)\n",
    "            print('----',i,' / ',length,'------')\n",
    "            print(text)\n",
    "            print('----------------------')\n",
    "        except:\n",
    "            reviews.append(np.nan)\n",
    "        i+=1\n",
    "    except:\n",
    "        driver.refresh()\n",
    "\n",
    "to_save=pd.DataFrame({'reviews':reviews})  \n",
    "\n",
    "to_save.to_csv('Try5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219494b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "i=1\n",
    "for l in links6:\n",
    "    try:\n",
    "        driver.get(l)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            text=driver.find_element(By.CLASS_NAME,'reviewText').text\n",
    "            reviews.append(text)\n",
    "            print('----',i,' / ',length,'------')\n",
    "            print(text)\n",
    "            print('----------------------')\n",
    "        except:\n",
    "            reviews.append(np.nan)\n",
    "        i+=1\n",
    "    except:\n",
    "        driver.refresh()\n",
    "\n",
    "to_save=pd.DataFrame({'reviews':reviews})  \n",
    "\n",
    "to_save.to_csv('Try6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab705772",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(new_df[100000:125000].index,inplace=True)\n",
    "new_df.drop(new_df[99846:100000].index,inplace=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5a6ae9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=pd.read_csv('Try1.csv')\n",
    "s2=pd.read_csv('Try2.csv')\n",
    "s3=pd.read_csv('Try3.csv')\n",
    "s4=pd.read_csv('Try4.csv')\n",
    "s6=pd.read_csv('Try6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0683bbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124846"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs=[]\n",
    "\n",
    "r1=s1['reviews'].tolist()\n",
    "r2=s2['reviews'].tolist()\n",
    "r3=s3['reviews'].tolist()\n",
    "r4=s4['reviews'].tolist()\n",
    "r6=s6['reviews'].tolist()\n",
    "\n",
    "for item in r1:\n",
    "    revs.append(item)\n",
    "for item in r2:\n",
    "    revs.append(item)\n",
    "for item in r3:\n",
    "    revs.append(item)\n",
    "for item in r4:\n",
    "    revs.append(item)\n",
    "for item in r6:\n",
    "    revs.append(item)\n",
    "len(revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.insert(0,'Reviews',revs)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cffb1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('Complete_df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
